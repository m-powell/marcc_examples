#!/bin/bash -l

#SBATCH
#SBATCH --job-name=nd_example
#SBATCH --time=0:10:0
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=2
#SBATCH --partition=express
#SBATCH --mail-type=<>
#SBATCH --mail-user=<>

##
## This is used for setup between MARCC and dev on my local box.
## 

## n is starting job_id
## N is stop job_id
## M is the max number of jobs to run concurrently 
## To submit this at the command line run:
## sbatch --array=n-N%M slurmScript.scr 

export PARAMS_FILE="runParameters.dat"
export OUTDIR="output/"


## if statement so parameters are different on my laptop
if [[ "$USER" == "jpatsol1@jhu.edu" ]]; then
	module load python/3.8
	source ~/env/bin/activate
	dataID=$(awk '{print $1}' $PARAMS_FILE | sed "$SLURM_ARRAY_TASK_ID q;d")
	runID=$(awk '{print $2}' $PARAMS_FILE | sed "$SLURM_ARRAY_TASK_ID q;d") 
elif [[ "$USER" == "JLP" ]]; then
    SLURM_NTASKS=2
	## read the first line of DATFILE for dev
	dataID=$(awk '{print $1}' $PARAMS_FILE | sed "1 q;d") 
	runID=$(awk '{print $2}' $PARAMS_FILE | sed "1 q;d") 
fi

## python skrf.py <outdir> <dataid> <runid> <njobs>
python skrf.py $OUTDIR $dataID $runID $SLURM_NTASKS
